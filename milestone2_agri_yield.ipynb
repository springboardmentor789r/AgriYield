{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9193b7",
   "metadata": {},
   "source": [
    "# Milestone 2 — Crop Yield: ML Pipelines + Time-Series Analysis\n",
    "**Author:** Arup Kanungo  \n",
    "**Branch:** `intern-ArupKanungo`  \n",
    "**Notebook filename (suggested):** `milestone2_agri_yield.ipynb`\n",
    "\n",
    "This notebook:\n",
    "- compares pipelines (OneHot+Standard + RF vs LeaveOneOut+MinMax + RF),\n",
    "- evaluates several regressors,\n",
    "- builds a final sklearn `Pipeline`,\n",
    "- prepares a daily time-series, runs stationarity tests (ADF, KPSS), ACF/PACF,\n",
    "- fits ARIMA baseline and runs `auto_arima`,\n",
    "- saves outputs and provides git commands to push to the project repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once in Colab\n",
    "%pip install -q category_encoders pmdarima xgboost lightgbm catboost statsmodels joblib\n",
    "print(\"Dependencies installed (or were already present).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a8f68",
   "metadata": {},
   "source": [
    "## 1) Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# optional boosters\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception:\n",
    "    XGBRegressor = None\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "# time-series\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# persistence\n",
    "import joblib\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "\n",
    "# Paths / outputs\n",
    "OUTPUT_DIR = \"/content/milestone2_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "PREPROCESSED_CSV = \"/content/preprocessed_crop_data.csv\"   # change if needed\n",
    "RAW_CSV = \"/content/crop_yield_dataset.csv\"               # fallback raw csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57045542",
   "metadata": {},
   "source": [
    "## 2) Load dataset (preprocessed if available; otherwise raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2179bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed if exists, else load raw\n",
    "if os.path.exists(PREPROCESSED_CSV):\n",
    "    print(\"Loading preprocessed CSV:\", PREPROCESSED_CSV)\n",
    "    df = pd.read_csv(PREPROCESSED_CSV)\n",
    "else:\n",
    "    print(\"Preprocessed not found. Loading raw CSV:\", RAW_CSV)\n",
    "    df = pd.read_csv(RAW_CSV)\n",
    "\n",
    "print(\"Initial shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Basic checks\n",
    "if 'Crop_Yield' not in df.columns:\n",
    "    raise RuntimeError(\"Expected column 'Crop_Yield' missing. Fix CSV path or column name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978da63",
   "metadata": {},
   "source": [
    "## 3) Data cleaning: drop zero-yield rows and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43778405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where Crop_Yield == 0\n",
    "before = len(df)\n",
    "df = df[df['Crop_Yield'] != 0].reset_index(drop=True)\n",
    "print(f\"Dropped {before - len(df)} rows with zero yield. Remaining rows: {len(df)}\")\n",
    "\n",
    "# Quick dtypes and missing summary\n",
    "print(\"\\nDtypes:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill numeric NaNs with mean, categorical with \"Unknown\" (we'll refine per pipeline)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"\\nNumeric cols (auto):\", num_cols)\n",
    "print(\"Categorical cols (auto):\", cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e55bf",
   "metadata": {},
   "source": [
    "## 4) Prepare ML dataset: select categorical & numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ee9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical expected lists; adjust if names differ\n",
    "expected_num = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
    "expected_cat = [c for c in ['Crop_Type','Soil_Type'] if c in df.columns]\n",
    "\n",
    "# Use expected if available, else infer numeric columns minus target\n",
    "if set(expected_num).issubset(set(df.columns)):\n",
    "    numerical_features = expected_num\n",
    "else:\n",
    "    numerical_features = [c for c in num_cols if c != 'Crop_Yield']\n",
    "\n",
    "categorical_features = expected_cat\n",
    "\n",
    "print(\"Numerical features used:\", numerical_features)\n",
    "print(\"Categorical features used:\", categorical_features)\n",
    "\n",
    "# Create ML DF (drop Date if present)\n",
    "ml_df = df.copy()\n",
    "if 'Date' in ml_df.columns:\n",
    "    ml_df = ml_df.drop(columns=['Date'])\n",
    "# Fill missing\n",
    "ml_df[numerical_features] = ml_df[numerical_features].fillna(ml_df[numerical_features].mean())\n",
    "for c in categorical_features:\n",
    "    ml_df[c] = ml_df[c].fillna(\"Unknown\")\n",
    "print(\"ML DF shape:\", ml_df.shape)\n",
    "display(ml_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d2b62",
   "metadata": {},
   "source": [
    "## 5) Train/Test split (holdout) — 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ml_df.drop(columns=['Crop_Yield'])\n",
    "y = ml_df['Crop_Yield']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d578625a",
   "metadata": {},
   "source": [
    "## 6) Helper function — evaluate models (CV + holdout metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee40d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def evaluate_model(name, model, Xtr, Xte, ytr, yte, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    try:\n",
    "        scores = cross_val_score(model, Xtr, ytr, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1)\n",
    "        cv_rmse = np.mean(np.sqrt(-scores))\n",
    "    except Exception:\n",
    "        cv_rmse = np.nan\n",
    "    model.fit(Xtr, ytr)\n",
    "    preds = model.predict(Xte)\n",
    "    r2 = r2_score(yte, preds)\n",
    "    mae = mean_absolute_error(yte, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(yte, preds))\n",
    "    print(f\"{name:30s} | CV_RMSE: {cv_rmse:8.4f} | Test RMSE: {rmse:8.4f} | MAE: {mae:8.4f} | R2: {r2:8.4f}\")\n",
    "    return {'name': name, 'cv_rmse': cv_rmse, 'test_rmse': rmse, 'mae': mae, 'r2': r2, 'preds': preds, 'model': model}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0be9cb",
   "metadata": {},
   "source": [
    "## 7) Build two pipelines to test\n",
    "- **Pipeline A**: OneHotEncoder (categorical) + StandardScaler (numerical) + RandomForest\n",
    "- **Pipeline B**: LeaveOneOutEncoder (categorical) + MinMaxScaler (numerical) + RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline A: OneHot + Standard + RF\n",
    "preproc_A = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "pipe_A = Pipeline([\n",
    "    ('preproc', preproc_A),\n",
    "    ('model', RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Pipeline B: LeaveOneOut + MinMax + RF\n",
    "preproc_B = ColumnTransformer(transformers=[\n",
    "    ('num', MinMaxScaler(), numerical_features),\n",
    "    ('cat', ce.LeaveOneOutEncoder(cols=categorical_features, sigma=0.1), categorical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "pipe_B = Pipeline([\n",
    "    ('preproc', preproc_B),\n",
    "    ('model', RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Pipelines defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b241de",
   "metadata": {},
   "source": [
    "## 8) Evaluate the two pipelines (mentor suggested & alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print(\"\\nEvaluating Pipeline A (OneHot + Standard + RF):\")\n",
    "resA = evaluate_model(\"OneHot+Std+RF\", pipe_A, X_train, X_test, y_train, y_test)\n",
    "results.append(resA)\n",
    "\n",
    "print(\"\\nEvaluating Pipeline B (LOO + MinMax + RF):\")\n",
    "resB = evaluate_model(\"LOO+MinMax+RF\", pipe_B, X_train, X_test, y_train, y_test)\n",
    "results.append(resB)\n",
    "\n",
    "comp_df = pd.DataFrame([{'pipeline': r['name'], 'cv_rmse': r['cv_rmse'], 'test_rmse': r['test_rmse'], 'mae': r['mae'], 'r2': r['r2']} for r in results])\n",
    "display(comp_df)\n",
    "comp_df.to_csv(os.path.join(OUTPUT_DIR, \"pipeline_comparison_initial.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90441b",
   "metadata": {},
   "source": [
    "## 9) Visualize pipeline comparison (Test RMSE & R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(data=comp_df, x='pipeline', y='test_rmse')\n",
    "plt.title('Test RMSE by Pipeline')\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot(data=comp_df, x='pipeline', y='r2')\n",
    "plt.title('R² by Pipeline')\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341d49b",
   "metadata": {},
   "source": [
    "## 10) Sweep several regressors using Pipeline A (OneHot + Standard)\n",
    "We try: LinearRegression, Ridge, Lasso, DecisionTree, RandomForest, (XGBoost optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e56d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_preproc = preproc_A\n",
    "models_to_try = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.01),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "}\n",
    "if XGBRegressor is not None:\n",
    "    models_to_try[\"XGBoost\"] = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "ml_results = []\n",
    "for name, estimator in models_to_try.items():\n",
    "    pipeline = Pipeline([('preproc', base_preproc), ('model', estimator)])\n",
    "    res = evaluate_model(name, pipeline, X_train, X_test, y_train, y_test)\n",
    "    ml_results.append(res)\n",
    "\n",
    "ml_df = pd.DataFrame([{'model': r['name'], 'cv_rmse': r['cv_rmse'], 'test_rmse': r['test_rmse'], 'mae': r['mae'], 'r2': r['r2']} for r in ml_results]).sort_values('test_rmse')\n",
    "display(ml_df)\n",
    "ml_df.to_csv(os.path.join(OUTPUT_DIR, \"ml_model_comparison.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5334fd45",
   "metadata": {},
   "source": [
    "## 11) Choose best model by test RMSE, show predictions, and save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick best by smallest test_rmse\n",
    "best_row = ml_df.iloc[0]\n",
    "best_name = best_row['model']\n",
    "print(\"Best model by test RMSE:\", best_name)\n",
    "\n",
    "best_estimator = models_to_try[best_name]\n",
    "best_pipeline = Pipeline([('preproc', base_preproc), ('model', best_estimator)])\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "metrics = {'r2': r2_score(y_test, y_pred),\n",
    "           'mae': mean_absolute_error(y_test, y_pred),\n",
    "           'rmse': np.sqrt(mean_squared_error(y_test, y_pred))}\n",
    "print(\"Test metrics (best):\", metrics)\n",
    "\n",
    "# Save predictions\n",
    "pred_df = X_test.copy()\n",
    "pred_df['y_true'] = y_test.values\n",
    "pred_df['y_pred'] = y_pred\n",
    "pred_path = os.path.join(OUTPUT_DIR, \"best_pipeline_predictions.csv\")\n",
    "pred_df.to_csv(pred_path, index=False)\n",
    "print(\"Saved predictions to:\", pred_path)\n",
    "\n",
    "# Save the best pipeline\n",
    "pipeline_path = os.path.join(OUTPUT_DIR, f\"best_pipeline_{best_name.replace(' ','_')}.joblib\")\n",
    "joblib.dump(best_pipeline, pipeline_path)\n",
    "print(\"Saved best pipeline to:\", pipeline_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e8a33",
   "metadata": {},
   "source": [
    "## 12) Time-series: prepare daily series and test stationarity (ADF, KPSS), plot ACF/PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fa599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date' in df.columns:\n",
    "    ts = df.copy()\n",
    "    ts['Date'] = pd.to_datetime(ts['Date'], errors='coerce')\n",
    "    ts = ts.dropna(subset=['Date']).set_index('Date')\n",
    "    ts_daily = ts.resample('D').mean()\n",
    "    ts_daily.to_csv(os.path.join(OUTPUT_DIR, \"preprocessed_timeseries.csv\"))\n",
    "    print(\"Saved daily timeseries to:\", os.path.join(OUTPUT_DIR, \"preprocessed_timeseries.csv\"))\n",
    "    display(ts_daily.head())\n",
    "\n",
    "    # Choose series\n",
    "    series = ts_daily['Crop_Yield'].dropna()\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(series, color='darkgreen')\n",
    "    plt.title('Daily Crop_Yield')\n",
    "    plt.show()\n",
    "\n",
    "    # ADF\n",
    "    print(\"\\nAugmented Dickey-Fuller test:\")\n",
    "    adf_res = adfuller(series)\n",
    "    print(\"ADF stat:\", adf_res[0], \"p-value:\", adf_res[1])\n",
    "    for k,v in adf_res[4].items():\n",
    "        print(k, v)\n",
    "    print(\"=> stationary if p < 0.05\")\n",
    "\n",
    "    # KPSS\n",
    "    print(\"\\nKPSS test:\")\n",
    "    try:\n",
    "        kpss_res = kpss(series, regression='c', nlags='auto')\n",
    "        print(\"KPSS stat:\", kpss_res[0], \"p-value:\", kpss_res[1])\n",
    "        for k,v in kpss_res[3].items():\n",
    "            print(k, v)\n",
    "    except Exception as e:\n",
    "        print(\"KPSS test error:\", e)\n",
    "    print(\"=> KPSS stationary if p > 0.05\")\n",
    "\n",
    "    # ACF / PACF\n",
    "    fig, axes = plt.subplots(1,2,figsize=(12,4))\n",
    "    plot_acf(series, lags=30, ax=axes[0])\n",
    "    plot_pacf(series, lags=30, ax=axes[1])\n",
    "    axes[0].set_title('ACF')\n",
    "    axes[1].set_title('PACF')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Date column not present — skipping time-series steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2389826b",
   "metadata": {},
   "source": [
    "## 13) ARIMA baseline & auto_arima (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date' in df.columns:\n",
    "    try:\n",
    "        print(\"Fitting ARIMA(1,0,1)...\")\n",
    "        arima_model = ARIMA(series, order=(1,0,1))\n",
    "        arima_fit = arima_model.fit()\n",
    "        print(arima_fit.summary())\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.plot(series, label='Actual')\n",
    "        plt.plot(arima_fit.fittedvalues, color='r', label='Fitted')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"ARIMA failed:\", e)\n",
    "\n",
    "    # auto_arima (can be slow)\n",
    "    try:\n",
    "        print(\"Running auto_arima (may take time)...\")\n",
    "        auto_res = auto_arima(series, seasonal=False, trace=False, error_action='ignore', suppress_warnings=True, max_p=5, max_q=5)\n",
    "        print(auto_res.summary())\n",
    "    except Exception as e:\n",
    "        print(\"auto_arima failed or took long:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acdb37a",
   "metadata": {},
   "source": [
    "## 14) Save important outputs (CSV + pipeline files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already saved earlier; list output folder\n",
    "print(\"Files in\", OUTPUT_DIR)\n",
    "print(os.listdir(OUTPUT_DIR))\n",
    "\n",
    "# Save ml_df and comp_df if present\n",
    "if 'ml_df' in globals():\n",
    "    ml_df.to_csv(os.path.join(OUTPUT_DIR, \"ml_model_comparison_sorted.csv\"), index=False)\n",
    "print(\"Saved model comparisons.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676508c6",
   "metadata": {},
   "source": [
    "## 15) Git: push notebook to GitHub branch `intern-ArupKanungo`\n",
    "**Important:** For pushing from Colab you need a GitHub Personal Access Token (PAT) with repo permissions.\n",
    "1. Create a PAT in your GitHub account (Settings → Developer settings → Personal access tokens → repo scope).\n",
    "2. Run the cell below and paste the token when prompted. The token is used only in this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03003076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURE THESE ---\n",
    "GIT_REPO_URL = \"https://github.com/springboardmentor789r/AgriYield.git\"\n",
    "BRANCH_NAME = \"intern-ArupKanungo\"\n",
    "NOTEBOOK_FILENAME = \"milestone2_agri_yield.ipynb\"  # ensure your Colab notebook is named this before running\n",
    "\n",
    "# 1) Ask for PAT securely\n",
    "from getpass import getpass\n",
    "token = getpass(\"Enter your GitHub Personal Access Token (will not echo): \")\n",
    "\n",
    "# 2) Clone the repo (or pull if exists) into /content/repo\n",
    "REPO_DIR = \"/content/AgriYield\"\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(\"Repo directory exists — pulling latest changes.\")\n",
    "    %cd {REPO_DIR}\n",
    "    !git pull\n",
    "    %cd /content\n",
    "else:\n",
    "    # clone with token in URL (private repo access)\n",
    "    clone_url = GIT_REPO_URL.replace(\"https://\", f\"https://{token}@\")\n",
    "    print(\"Cloning:\", GIT_REPO_URL)\n",
    "    !git clone {clone_url} {REPO_DIR}\n",
    "    # remove token from history (just in case)\n",
    "    %cd /content\n",
    "\n",
    "# 3) Create branch and switch to it\n",
    "%cd {REPO_DIR}\n",
    "!git checkout -b {BRANCH_NAME}\n",
    "\n",
    "# 4) Copy this notebook file into the repo folder\n",
    "import shutil\n",
    "src_nb_path = f\"/content/{NOTEBOOK_FILENAME}\"\n",
    "dest_nb_path = f\"{REPO_DIR}/{NOTEBOOK_FILENAME}\"\n",
    "if os.path.exists(src_nb_path):\n",
    "    shutil.copy(src_nb_path, dest_nb_path)\n",
    "    print(\"Copied notebook to repo:\", dest_nb_path)\n",
    "else:\n",
    "    print(\"Notebook file not found at\", src_nb_path)\n",
    "    print(\"Make sure your notebook is saved with name:\", NOTEBOOK_FILENAME)\n",
    "\n",
    "# 5) Stage, commit, push\n",
    "!git add -A\n",
    "!git commit -m \"Milestone 2: pipelines + timeseries - Arup Kanungo\" || true\n",
    "push_url = GIT_REPO_URL.replace(\"https://\", f\"https://{token}@\")\n",
    "!git push {push_url} {BRANCH_NAME}\n",
    "\n",
    "print(\"Done. If push succeeded, visit the repo to create a Pull Request.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c8c63",
   "metadata": {},
   "source": [
    "## Final Notes & Next Steps\n",
    "- If push fails due to permission or token issues, double-check PAT scopes (repo) and branch name.\n",
    "- After pushing, open GitHub → repo → \"Compare & pull request\" to create PR.\n",
    "- If you want, I can convert this notebook to a downloadable `.ipynb` file for you."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
