{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor789r/AgriYield/blob/Intern_LikhitaKoppuravuri/PreprocessedRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBkuEYXrMuUo",
        "outputId": "145a62fe-f9f3-4743-d5b0-c791c79a5638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out with min max scaling-lasso regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "target_col = 'Crop_Yield'\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "def leave_one_out_encode(train_df, X_test, target_col, categorical_cols):\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    X_train_encoded = X_train.copy().drop(categorical_cols, axis=1)\n",
        "    X_test_encoded = X_test.copy().drop(categorical_cols, axis=1)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = train_df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        s_i_map = X_train[col].map(S_i)\n",
        "        n_i_map = X_train[col].map(N_i)\n",
        "        N_minus_1_count = n_i_map - 1\n",
        "        S_minus_y = s_i_map - y_train\n",
        "        looe_train = np.where(N_minus_1_count == 0, global_mean, S_minus_y / N_minus_1_count)\n",
        "        X_train_encoded[f'{col}_Encoded'] = looe_train\n",
        "        mean_map = (S_i / N_i).to_dict()\n",
        "        X_test_encoded[f'{col}_Encoded'] = X_test[col].map(mean_map).fillna(global_mean)\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "X_train_encoded, X_test_encoded = leave_one_out_encode(train_df, X_test, target_col, categorical_cols)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_encoded.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_encoded.columns)\n",
        "lasso_model = Lasso(alpha=1.0, random_state=42, max_iter=5000)\n",
        "lasso_model.fit(X_train_scaled, y_train)\n",
        "y_pred = lasso_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Lasso Regression Model (LOOE + MinMax Scaling, alpha=1.0) Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2:.4f}\")\n",
        "coefficients = pd.Series(lasso_model.coef_, index=X_train_scaled.columns)\n",
        "print(\"\\nModel Coefficients (Lasso, alpha=1.0):\")\n",
        "print(coefficients[coefficients != 0].sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1gIzelqiV9W",
        "outputId": "86510d34-ca27-4111-b616-95ae7c760d3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Regression Model (LOOE + MinMax Scaling, alpha=1.0) Performance:\n",
            "Mean Squared Error (MSE): 422.43\n",
            "Root Mean Squared Error (RMSE): 20.55\n",
            "R-squared ($R^2$): 0.1638\n",
            "\n",
            "Model Coefficients (Lasso, alpha=1.0):\n",
            "Soil_Type_Encoded    13.602969\n",
            "Humidity             10.501559\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with min max scaling-ridge regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "target_col = 'Crop_Yield'\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "def leave_one_out_encode(train_df, X_test, target_col, categorical_cols):\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    X_train_encoded = X_train.copy().drop(categorical_cols, axis=1)\n",
        "    X_test_encoded = X_test.copy().drop(categorical_cols, axis=1)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = train_df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        s_i_map = X_train[col].map(S_i)\n",
        "        n_i_map = X_train[col].map(N_i)\n",
        "        N_minus_1_count = n_i_map - 1\n",
        "        S_minus_y = s_i_map - y_train\n",
        "        looe_train = np.where(N_minus_1_count == 0, global_mean, S_minus_y / N_minus_1_count)\n",
        "        X_train_encoded[f'{col}_Encoded'] = looe_train\n",
        "        mean_map = (S_i / N_i).to_dict()\n",
        "        X_test_encoded[f'{col}_Encoded'] = X_test[col].map(mean_map).fillna(global_mean)\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "X_train_encoded, X_test_encoded = leave_one_out_encode(train_df, X_test, target_col, categorical_cols)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_encoded.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_encoded.columns)\n",
        "ridge_model = Ridge(alpha=1.0, random_state=42)\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "y_pred = ridge_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Ridge Regression Model (LOOE + MinMax Scaling, alpha=1.0) Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2:.4f}\")\n",
        "coefficients = pd.Series(ridge_model.coef_, index=X_train_scaled.columns)\n",
        "print(\"\\nModel Coefficients (Ridge, alpha=1.0):\")\n",
        "print(coefficients.sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RI4r4Xji2Du",
        "outputId": "9e9f7811-d30c-4ef8-e8e0-a257f879f2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression Model (LOOE + MinMax Scaling, alpha=1.0) Performance:\n",
            "Mean Squared Error (MSE): 214.75\n",
            "Root Mean Squared Error (RMSE): 14.65\n",
            "R-squared ($R^2$): 0.5749\n",
            "\n",
            "Model Coefficients (Ridge, alpha=1.0):\n",
            "Temperature          150.444116\n",
            "Humidity             147.486490\n",
            "Soil_Type_Encoded     14.587174\n",
            "Crop_Type_Encoded      6.320599\n",
            "Soil_Quality           5.956243\n",
            "P                      4.154711\n",
            "N                      0.987193\n",
            "K                      0.454921\n",
            "Soil_pH               -0.049528\n",
            "Wind_Speed            -0.920407\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with min max scaling-random forest regressor\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "target_col = 'Crop_Yield'\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "def leave_one_out_encode(train_df, X_test, target_col, categorical_cols):\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    X_train_encoded = X_train.copy().drop(categorical_cols, axis=1)\n",
        "    X_test_encoded = X_test.copy().drop(categorical_cols, axis=1)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = train_df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        s_i_map = X_train[col].map(S_i)\n",
        "        n_i_map = X_train[col].map(N_i)\n",
        "        N_minus_1_count = n_i_map - 1\n",
        "        S_minus_y = s_i_map - y_train\n",
        "        looe_train = np.where(N_minus_1_count == 0, global_mean, S_minus_y / N_minus_1_count)\n",
        "        X_train_encoded[f'{col}_Encoded'] = looe_train\n",
        "        mean_map = (S_i / N_i).to_dict()\n",
        "        X_test_encoded[f'{col}_Encoded'] = X_test[col].map(mean_map).fillna(global_mean)\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "X_train_encoded, X_test_encoded = leave_one_out_encode(train_df, X_test, target_col, categorical_cols)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_encoded.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_encoded.columns)\n",
        "rf_regressor = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "rf_regressor.fit(X_train_scaled, y_train)\n",
        "y_pred = rf_regressor.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Random Forest Regressor (LOOE + MinMax Scaling) Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2:.4f}\")\n",
        "importances = pd.Series(rf_regressor.feature_importances_, index=X_train_scaled.columns)\n",
        "print(\"\\nFeature Importances:\")\n",
        "print(importances.sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Sy8DH4jlhw",
        "outputId": "b03fd3ed-cb5b-4203-f12f-1230e968f5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor (LOOE + MinMax Scaling) Performance:\n",
            "Mean Squared Error (MSE): 267.93\n",
            "Root Mean Squared Error (RMSE): 16.37\n",
            "R-squared ($R^2$): 0.4697\n",
            "\n",
            "Feature Importances:\n",
            "Temperature          0.392911\n",
            "Soil_Type_Encoded    0.289648\n",
            "Soil_Quality         0.136310\n",
            "Crop_Type_Encoded    0.078271\n",
            "Humidity             0.045757\n",
            "N                    0.025887\n",
            "Soil_pH              0.020165\n",
            "P                    0.009380\n",
            "K                    0.001571\n",
            "Wind_Speed           0.000099\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with random forest regression with pipeline\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "df = pd.read_excel('crop_yield_dataset.csv1.xlsm')\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', StandardScaler(), numerical_cols),\n",
        "    ('cat', LeaveOneOutEncoder(), categorical_cols)\n",
        "])\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [100],\n",
        "    'regressor__max_depth': [10, None],\n",
        "    'regressor__min_samples_split': [2],\n",
        "    'regressor__min_samples_leaf': [1]\n",
        "}\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R-squared (R²): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyImmjXAYK5H",
        "outputId": "f6484582-c8ad-45e1-eabf-21e2d3e19924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 100}\n",
            "Test MSE: 253.4183\n",
            "Best Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 100}\n",
            "Mean Squared Error (MSE): 253.4183\n",
            "Root Mean Squared Error (RMSE): 15.9191\n",
            "Mean Absolute Error (MAE): 11.6821\n",
            "R-squared (R²): 0.4984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with min max scaler-random forest regression with pipeline\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "df = pd.read_excel('crop_yield_dataset.csv1.xlsm')\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', MinMaxScaler(), numerical_cols),\n",
        "    ('cat', LeaveOneOutEncoder(), categorical_cols)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [100],\n",
        "    'regressor__max_depth': [10, None],\n",
        "    'regressor__min_samples_split': [2, 5],\n",
        "    'regressor__min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R-squared (R²): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGOd7hI1aEVp",
        "outputId": "f3fcfa60-7365-4d04-eaa5-fbb2c578e0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 2, 'regressor__min_samples_split': 5, 'regressor__n_estimators': 100}\n",
            "Mean Squared Error (MSE): 253.1716\n",
            "Root Mean Squared Error (RMSE): 15.9114\n",
            "Mean Absolute Error (MAE): 11.6671\n",
            "R-squared (R²): 0.4989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with min max scaling-random forest without pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "df = pd.read_excel('crop_yield_dataset.csv1.xlsm')\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "encoder = LeaveOneOutEncoder(cols=categorical_cols)\n",
        "X_train_cat_encoded = encoder.fit_transform(X_train[categorical_cols], y_train)\n",
        "X_test_cat_encoded = encoder.transform(X_test[categorical_cols])\n",
        "scaler = MinMaxScaler()\n",
        "X_train_num_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test_num_scaled = scaler.transform(X_test[numerical_cols])\n",
        "X_train_processed = np.hstack((X_train_num_scaled, X_train_cat_encoded))\n",
        "X_test_processed = np.hstack((X_test_num_scaled, X_test_cat_encoded))\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [10, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_processed)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R-squared (R²): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKF-jgVcb4WC",
        "outputId": "208fdd11-e014-4522-d6c4-3b67001b6b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Mean Squared Error (MSE): 267.8733\n",
            "Root Mean Squared Error (RMSE): 16.3668\n",
            "Mean Absolute Error (MAE): 12.3133\n",
            "R-squared (R²): 0.4698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.head())\n",
        "print(y_train.isna().sum())\n",
        "print(y_train.dtype)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzgFDM1UjIGK",
        "outputId": "e349d612-4830-4082-a586-5f8b04dcb588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13222    27.916667\n",
            "3295     37.041667\n",
            "4401     14.583333\n",
            "2310     22.500000\n",
            "15429    13.916667\n",
            "Name: Soil_Quality, dtype: float64\n",
            "0\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with linear regression\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df_processed = df.drop('Date', axis=1)\n",
        "X = df_processed.drop('Crop_Yield', axis=1)\n",
        "y = df_processed['Crop_Yield']\n",
        "full_df = df_processed.copy()\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "target_col = 'Crop_Yield'\n",
        "def leave_one_out_encode_full(df, target_col, categorical_cols):\n",
        "    df_encoded = df.drop(target_col, axis=1).copy()\n",
        "    global_mean = df[target_col].mean()\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        df_encoded[f'{col}_sum'] = df_encoded[col].map(S_i)\n",
        "        df_encoded[f'{col}_count'] = df_encoded[col].map(N_i)\n",
        "        N_minus_1 = df_encoded[f'{col}_count'] - 1\n",
        "        S_minus_y = df_encoded[f'{col}_sum'] - df[target_col]\n",
        "        looe = np.where(N_minus_1 == 0, global_mean, S_minus_y / N_minus_1)\n",
        "        df_encoded[f'{col}_Encoded'] = looe\n",
        "        df_encoded = df_encoded.drop([col, f'{col}_sum', f'{col}_count'], axis=1)\n",
        "\n",
        "    return df_encoded\n",
        "X_encoded = leave_one_out_encode_full(full_df, target_col, categorical_cols)\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_encoded, y)\n",
        "y_pred_full = linear_model.predict(X_encoded)\n",
        "mse_full = mean_squared_error(y, y_pred_full)\n",
        "rmse_full = np.sqrt(mse_full)\n",
        "r2_full = r2_score(y, y_pred_full)\n",
        "print(f\"--- Results on the Complete Dataset (In-Sample Performance) ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_full:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_full:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2_full:.4f}\")\n",
        "coefficients_full = pd.Series(linear_model.coef_, index=X_encoded.columns)\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(coefficients_full)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MSoZeG0aNdG",
        "outputId": "d22913dd-5888-49af-eae6-76b2f10dd161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Results on the Complete Dataset (In-Sample Performance) ---\n",
            "Mean Squared Error (MSE): 217.20\n",
            "Root Mean Squared Error (RMSE): 14.74\n",
            "R-squared ($R^2$): 0.5670\n",
            "\n",
            "Model Coefficients:\n",
            "Soil_pH             -0.023937\n",
            "Temperature          6.090198\n",
            "Humidity             9.949944\n",
            "Wind_Speed          -0.014758\n",
            "N                    0.003710\n",
            "P                    0.186517\n",
            "K                   -0.013511\n",
            "Soil_Quality         0.105804\n",
            "Crop_Type_Encoded    0.618596\n",
            "Soil_Type_Encoded    0.659791\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with standard scaling-logistic regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "median_yield = df['Crop_Yield'].median()\n",
        "df['High_Yield'] = (df['Crop_Yield'] > median_yield).astype(int)\n",
        "X = df.drop(['Crop_Yield', 'High_Yield'], axis=1)\n",
        "y = df['High_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "target_col = 'High_Yield'\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "def leave_one_out_encode(train_df, X_test, target_col, categorical_cols):\n",
        "    # Calculate the global mean of the binary target in the training set\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    X_train_encoded = X_train.copy().drop(categorical_cols, axis=1)\n",
        "    X_test_encoded = X_test.copy().drop(categorical_cols, axis=1)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = train_df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        s_i_map = X_train[col].map(S_i)\n",
        "        n_i_map = X_train[col].map(N_i)\n",
        "        N_minus_1 = n_i_map - y_train # Here, y_train is 0 or 1, but we need n_i_map - 1 for count\n",
        "        N_minus_1_count = n_i_map - 1\n",
        "        S_minus_y = s_i_map - y_train\n",
        "        looe_train = np.where(N_minus_1_count == 0, global_mean, S_minus_y / N_minus_1_count)\n",
        "        X_train_encoded[f'{col}_Encoded'] = looe_train\n",
        "        mean_map = (S_i / N_i).to_dict()\n",
        "        X_test_encoded[f'{col}_Encoded'] = X_test[col].map(mean_map).fillna(global_mean)\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "X_train_encoded, X_test_encoded = leave_one_out_encode(train_df, X_test, target_col, categorical_cols)\n",
        "scaler = StandardScaler()\n",
        "X_train_encoded[numerical_cols] = scaler.fit_transform(X_train_encoded[numerical_cols])\n",
        "X_test_encoded[numerical_cols] = scaler.transform(X_test_encoded[numerical_cols])\n",
        "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "logreg.fit(X_train_encoded, y_train)\n",
        "y_pred = logreg.predict(X_test_encoded)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Logistic Regression Model (LOOE + Scaling) Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykw1JscwbhHR",
        "outputId": "00d72ed9-e514-46e2-993b-8bad2c8d063a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model (LOOE + Scaling) Accuracy: 0.7953\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.79      2550\n",
            "           1       0.79      0.81      0.80      2549\n",
            "\n",
            "    accuracy                           0.80      5099\n",
            "   macro avg       0.80      0.80      0.80      5099\n",
            "weighted avg       0.80      0.80      0.80      5099\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encdoing with standard scaling-decision tree regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "target_col = 'Crop_Yield'\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "def leave_one_out_encode(train_df, X_test, target_col, categorical_cols):\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    X_train_encoded = X_train.copy().drop(categorical_cols, axis=1)\n",
        "    X_test_encoded = X_test.copy().drop(categorical_cols, axis=1)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = train_df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        s_i_map = X_train[col].map(S_i)\n",
        "        n_i_map = X_train[col].map(N_i)\n",
        "        N_minus_1_count = n_i_map - 1\n",
        "        S_minus_y = s_i_map - y_train\n",
        "        looe_train = np.where(N_minus_1_count == 0, global_mean, S_minus_y / N_minus_1_count)\n",
        "        X_train_encoded[f'{col}_Encoded'] = looe_train\n",
        "        mean_map = (S_i / N_i).to_dict()\n",
        "        X_test_encoded[f'{col}_Encoded'] = X_test[col].map(mean_map).fillna(global_mean)\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "X_train_encoded, X_test_encoded = leave_one_out_encode(train_df, X_test, target_col, categorical_cols)\n",
        "scaler = StandardScaler()\n",
        "X_train_encoded[numerical_cols] = scaler.fit_transform(X_train_encoded[numerical_cols])\n",
        "X_test_encoded[numerical_cols] = scaler.transform(X_test_encoded[numerical_cols])\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
        "dt_regressor.fit(X_train_encoded, y_train)\n",
        "y_pred = dt_regressor.predict(X_test_encoded)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Decision Tree Regressor (LOOE + Scaling, max_depth=10) Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfiHLRcbbq0W",
        "outputId": "0243d3de-5325-487d-a8c9-e19c10cb4b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor (LOOE + Scaling, max_depth=10) Performance:\n",
            "Mean Squared Error (MSE): 267.62\n",
            "Root Mean Squared Error (RMSE): 16.36\n",
            "R-squared ($R^2$): 0.4703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with standard scaling-support vector regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "target_col = 'Crop_Yield'\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "def leave_one_out_encode(train_df, X_test, target_col, categorical_cols):\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    X_train_encoded = X_train.copy().drop(categorical_cols, axis=1)\n",
        "    X_test_encoded = X_test.copy().drop(categorical_cols, axis=1)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = train_df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        s_i_map = X_train[col].map(S_i)\n",
        "        n_i_map = X_train[col].map(N_i)\n",
        "        N_minus_1_count = n_i_map - 1\n",
        "        S_minus_y = s_i_map - y_train\n",
        "\n",
        "        looe_train = np.where(N_minus_1_count == 0, global_mean, S_minus_y / N_minus_1_count)\n",
        "        X_train_encoded[f'{col}_Encoded'] = looe_train\n",
        "        mean_map = (S_i / N_i).to_dict()\n",
        "        X_test_encoded[f'{col}_Encoded'] = X_test[col].map(mean_map).fillna(global_mean)\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "X_train_encoded, X_test_encoded = leave_one_out_encode(train_df, X_test, target_col, categorical_cols)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_encoded.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_encoded.columns)\n",
        "svr_model = LinearSVR(random_state=42, max_iter=5000, dual=False, loss='squared_epsilon_insensitive')\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "y_pred = svr_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Linear Support Vector Regressor (LOOE + Scaling) Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alrFfeDxb1dI",
        "outputId": "d61699e5-f151-4a39-8917-9772c7aad9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Support Vector Regressor (LOOE + Scaling) Performance:\n",
            "Mean Squared Error (MSE): 214.72\n",
            "Root Mean Squared Error (RMSE): 14.65\n",
            "R-squared ($R^2$): 0.5750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leave one out encoding with min max scaling -linear regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "target_col = 'Crop_Yield'\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "def leave_one_out_encode(train_df, X_test, target_col, categorical_cols):\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    X_train_encoded = X_train.copy().drop(categorical_cols, axis=1)\n",
        "    X_test_encoded = X_test.copy().drop(categorical_cols, axis=1)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        agg = train_df.groupby(col)[target_col].agg(['count', 'sum'])\n",
        "        N_i = agg['count']\n",
        "        S_i = agg['sum']\n",
        "        s_i_map = X_train[col].map(S_i)\n",
        "        n_i_map = X_train[col].map(N_i)\n",
        "        N_minus_1_count = n_i_map - 1\n",
        "        S_minus_y = s_i_map - y_train\n",
        "        looe_train = np.where(N_minus_1_count == 0, global_mean, S_minus_y / N_minus_1_count)\n",
        "        X_train_encoded[f'{col}_Encoded'] = looe_train\n",
        "        mean_map = (S_i / N_i).to_dict()\n",
        "        X_test_encoded[f'{col}_Encoded'] = X_test[col].map(mean_map).fillna(global_mean)\n",
        "\n",
        "    return X_train_encoded, X_test_encoded\n",
        "X_train_encoded, X_test_encoded = leave_one_out_encode(train_df, X_test, target_col, categorical_cols)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_encoded.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_encoded.columns)\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train_scaled, y_train)\n",
        "y_pred = linear_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Linear Regression Model (LOOE + MinMax Scaling) Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2:.4f}\")\n",
        "coefficients = pd.Series(linear_model.coef_, index=X_train_scaled.columns)\n",
        "print(\"\\nModel Coefficients (after MinMax Scaling):\")\n",
        "print(coefficients.sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "248urnygcWKp",
        "outputId": "d4bd67d0-5725-4dee-c243-c18962ef4c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Model (LOOE + MinMax Scaling) Performance:\n",
            "Mean Squared Error (MSE): 214.72\n",
            "Root Mean Squared Error (RMSE): 14.65\n",
            "R-squared ($R^2$): 0.5750\n",
            "\n",
            "Model Coefficients (after MinMax Scaling):\n",
            "Temperature          152.243177\n",
            "Humidity             149.034351\n",
            "Soil_Type_Encoded     14.770173\n",
            "Crop_Type_Encoded      6.403987\n",
            "Soil_Quality           5.782022\n",
            "P                      4.119808\n",
            "N                      0.945118\n",
            "K                      0.390199\n",
            "Soil_pH               -0.056447\n",
            "Wind_Speed            -0.918339\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding standard scaling-decision tree regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "df = pd.read_excel(\"crop_yield_dataset.csv1.xlsm\")\n",
        "df = df.drop('Date', axis=1)\n",
        "X = df.drop('Crop_Yield', axis=1)\n",
        "y = df['Crop_Yield']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
        "X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
        "train_cols = X_train_encoded.columns\n",
        "X_test_encoded = X_test_encoded.reindex(columns=train_cols, fill_value=0)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_encoded[numerical_cols])\n",
        "\n",
        "X_train_encoded[numerical_cols] = scaler.transform(X_train_encoded[numerical_cols])\n",
        "X_test_encoded[numerical_cols] = scaler.transform(X_test_encoded[numerical_cols])\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
        "dt_regressor.fit(X_train_encoded, y_train)\n",
        "y_pred = dt_regressor.predict(X_test_encoded)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Decision Tree Regressor (max_depth=10) Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared ($R^2$): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tySXwc7GbV0W",
        "outputId": "724511c4-c150-446a-f8d0-dbabfbfeaac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor (max_depth=10) Performance:\n",
            "Mean Squared Error (MSE): 29.42\n",
            "Root Mean Squared Error (RMSE): 5.42\n",
            "R-squared ($R^2$): 0.9418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding with standard scaling-logisteic regression\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"crop_yield_dataset.csv\")\n",
        "df = df.drop('Date', axis=1)\n",
        "median_yield = df['Crop_Yield'].median()\n",
        "df['High_Yield'] = (df['Crop_Yield'] > median_yield).astype(int)\n",
        "X = df.drop(['Crop_Yield', 'High_Yield'], axis=1)\n",
        "y = df['High_Yield']\n",
        "categorical_cols = ['Crop_Type', 'Soil_Type']\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "numerical_cols = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = X_encoded.copy()\n",
        "X_scaled[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
        "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "logreg.fit(X_scaled, y)\n",
        "y_pred_full = logreg.predict(X_scaled)\n",
        "accuracy_full = accuracy_score(y, y_pred_full)\n",
        "report_full = classification_report(y, y_pred_full)\n",
        "print(f\"--- Results on the Complete Dataset (In-Sample Performance) ---\")\n",
        "print(f\"Logistic Regression Model Accuracy: {accuracy_full:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_full)\n",
        "coefficients_full = pd.Series(logreg.coef_[0], index=X_scaled.columns)\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(coefficients_full.sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "txQTP4FAbLlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# --- Configuration ---\n",
        "# ✅ CORRECTED FILE NAME\n",
        "FILE_NAME = \"crop_yield_dataset.csv1.xlsm\"\n",
        "SHEET_NAME = 'crop_yield_dataset (1)'\n",
        "TARGET_COL = 'Crop_Yield'\n",
        "CAT_COLS = ['Crop_Type', 'Soil_Type']\n",
        "# All features the model expects:\n",
        "FEATURE_COLS = ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality', 'Crop_Type', 'Soil_Type']\n",
        "\n",
        "\n",
        "# --- 1. Training Block: Load, Preprocess, and Fit the Model ---\n",
        "\n",
        "def train_lasso_model():\n",
        "    \"\"\"Loads data, performs preprocessing (encoding/scaling), and fits the Lasso model.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Load the XLSM file\n",
        "        print(f\"1. Loading '{FILE_NAME}'...\")\n",
        "        # Use read_excel for the .xlsm file\n",
        "        df = pd.read_excel(FILE_NAME = \"crop_yield_dataset.csv1.xlsm\", sheet_name='crop_yield_dataset (1)', engine='openpyxl')\n",
        "\n",
        "        y = df[TARGET_COL]\n",
        "        # X includes all features, dropping 'Date'\n",
        "        X = df.drop(columns=[TARGET_COL, 'Date'], errors='ignore')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFATAL ERROR: Could not load the Excel file.\")\n",
        "        print(\"1. Ensure the file is uploaded to Colab.\")\n",
        "        print(f\"2. Check if the SHEET_NAME ('{SHEET_NAME}') is exactly correct.\")\n",
        "        print(f\"Error details: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # --- 1a. Leave One Out Encoding (LOOE) Substitute: Target Mean Encoding ---\n",
        "    # Store the means for use in the prediction step\n",
        "    fitted_target_means = {}\n",
        "\n",
        "    print(\"2. Performing Target Mean Encoding (LOOE Substitute)...\")\n",
        "    for col in CAT_COLS:\n",
        "        if col in X.columns:\n",
        "            # Calculate the mean of the target 'y' for each category\n",
        "            target_means = y.groupby(X[col]).mean()\n",
        "            fitted_target_means[col] = target_means\n",
        "            # Replace the categorical values with the calculated mean\n",
        "            X[col] = X[col].map(target_means)\n",
        "        else:\n",
        "            # This should only happen if your file structure is missing columns\n",
        "            print(f\"   Warning: Column '{col}' not found. Skipping encoding.\")\n",
        "\n",
        "    # --- 1b. Min Max Scaling ---\n",
        "    print(\"3. Performing Min Max Scaling on all features...\")\n",
        "\n",
        "    fitted_scaler = MinMaxScaler()\n",
        "\n",
        "    # Fit the scaler to ALL feature columns\n",
        "    X_scaled_array = fitted_scaler.fit_transform(X)\n",
        "    X_scaled = pd.DataFrame(X_scaled_array, columns=X.columns)\n",
        "\n",
        "    print(\"   Scaling complete.\")\n",
        "\n",
        "    # --- 1c. Lasso Regression Fit ---\n",
        "    print(\"4. Fitting Lasso Regression Model...\")\n",
        "    lasso = Lasso(alpha=0.1, random_state=42)\n",
        "    lasso.fit(X_scaled, y)\n",
        "    print(\"   Model training complete.\")\n",
        "\n",
        "    # Return all fitted objects needed for prediction\n",
        "    return lasso, fitted_scaler, fitted_target_means, X_scaled.columns.tolist()\n",
        "\n",
        "\n",
        "# --- 2. Prediction Block: Use Fitted Objects to Predict ---\n",
        "\n",
        "def predict_crop_yield(lasso_model, scaler, target_means, feature_order):\n",
        "    \"\"\"\n",
        "    Predicts Crop Yield for a single row of input parameters.\n",
        "\n",
        "    Replace the values in 'new_input_data' with your desired parameters.\n",
        "    \"\"\"\n",
        "    print(\"\\n\\n--- PREDICTION ---\")\n",
        "\n",
        "    # Define your input parameters (Features)\n",
        "    # 🌟🌟🌟 CHANGE THESE VALUES FOR YOUR PREDICTION 🌟🌟🌟\n",
        "    new_input_data = {\n",
        "        'Soil_pH': 6.5,\n",
        "        'Temperature': 25.0,\n",
        "        'Humidity': 80.0,\n",
        "        'Wind_Speed': 10.0,\n",
        "        'N': 90.0,\n",
        "        'P': 60.0,\n",
        "        'K': 50.0,\n",
        "        'Soil_Quality': 50.0,\n",
        "        'Crop_Type': 'Corn',\n",
        "        'Soil_Type': 'Loamy'\n",
        "    }\n",
        "\n",
        "    # Convert the new input into a DataFrame\n",
        "    new_df = pd.DataFrame([new_input_data])\n",
        "\n",
        "    # Ensure the columns are in the exact order the model was trained on\n",
        "    new_df = new_df[feature_order]\n",
        "\n",
        "    # 1. Apply Encoding\n",
        "    for col, means in target_means.items():\n",
        "        # Map the categorical value to its corresponding mean from training data\n",
        "        new_df[col] = new_df[col].map(means)\n",
        "        # Fallback for new/unknown categories (uses the average of all means)\n",
        "        if new_df[col].isnull().any():\n",
        "            new_df[col] = new_df[col].fillna(np.mean(list(means.values())))\n",
        "\n",
        "    # 2. Apply Scaling\n",
        "    new_df_scaled = scaler.transform(new_df)\n",
        "\n",
        "    # 3. Use the predict() function\n",
        "    predicted_yield = lasso_model.predict(new_df_scaled)\n",
        "\n",
        "    # 4. Display the result\n",
        "    print(\"\\n#################################\")\n",
        "    print(f\"The Predicted Crop Yield is: {predicted_yield[0]:.2f}\")\n",
        "    print(\"#################################\")\n",
        "\n",
        "# --- Execute ---\n",
        "\n",
        "# 1. Train the model and get the fitted components\n",
        "lasso_model, fitted_scaler, fitted_target_means, feature_order = train_lasso_model()\n",
        "\n",
        "# 2. Perform the prediction\n",
        "predict_crop_yield(lasso_model, fitted_scaler, fitted_target_means, feature_order)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qza-r2bGizWu",
        "outputId": "7fa8c68a-dbfd-4233-db2e-43ef9df19d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading 'crop_yield_dataset.csv1.xlsm'...\n",
            "\n",
            "FATAL ERROR: Could not load the Excel file.\n",
            "1. Ensure the file is uploaded to Colab.\n",
            "2. Check if the SHEET_NAME ('crop_yield_dataset (1)') is exactly correct.\n",
            "Error details: read_excel() got an unexpected keyword argument 'FILE_NAME'\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-1169179829.py\", line 27, in train_lasso_model\n",
            "    df = pd.read_excel(FILE_NAME = \"crop_yield_dataset.csv1.xlsm\", sheet_name='crop_yield_dataset (1)', engine='openpyxl')\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: read_excel() got an unexpected keyword argument 'FILE_NAME'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1169179829.py\", line 130, in <cell line: 0>\n",
            "    lasso_model, fitted_scaler, fitted_target_means, feature_order = train_lasso_model()\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1169179829.py\", line 38, in train_lasso_model\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1169179829.py\u001b[0m in \u001b[0;36mtrain_lasso_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Use read_excel for the .xlsm file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"crop_yield_dataset.csv1.xlsm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'crop_yield_dataset (1)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'openpyxl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: read_excel() got an unexpected keyword argument 'FILE_NAME'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1169179829.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# 1. Train the model and get the fitted components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mlasso_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted_target_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lasso_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1169179829.py\u001b[0m in \u001b[0;36mtrain_lasso_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error details: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}