# üåæ Crop Yield Prediction using Machine Learning

## üìò Project Overview
This project aims to **predict crop yield** based on environmental and soil parameters using multiple **Machine Learning regression models**.  
It demonstrates a complete **end-to-end ML workflow** ‚Äî from data preprocessing and feature engineering to model training, comparison, and deployment via a reusable pipeline.

---

## üß† Objective
Accurately estimate the crop yield for different crop and soil types given factors such as temperature, humidity, nutrients, and other environmental attributes.

---

## ‚öôÔ∏è Workflow Summary

### 1Ô∏è‚É£ Data Preprocessing (`crop_yield_dataset.csv`)
- **Loaded the dataset** using `pandas`.
- **Removed invalid records** (`Crop_Yield == 0`).
- **Checked for missing values**, duplicates, and outliers.
- **Renamed and standardized column names** (e.g., `Temperature ‚Üí temp`, `Wind_Speed ‚Üí wind_speed`).
- **Explored the dataset** using:
  - `.info()`, `.describe()`, `.value_counts()`
  - Distribution plots and bar charts (`matplotlib`).

---

### 2Ô∏è‚É£ Exploratory Data Analysis (EDA)
- **Visualized key patterns**:
  - Temperature variation over time.
  - Average crop yield by crop type.
  - Average soil quality by soil type.
  - Distribution of soil pH.
- Helped understand feature importance and possible scaling needs.

---

### 3Ô∏è‚É£ Encoding Categorical Features
Various encoding techniques were applied to handle categorical data efficiently:

| Encoding Type | Library | Description |
|----------------|----------|-------------|
| Label Encoding | `sklearn.preprocessing.LabelEncoder` | Encodes categories as integers. |
| One-Hot Encoding | `OneHotEncoder` | Expands categories into binary columns. |
| Binary Encoding | `category_encoders` | Converts categories into binary bits. |
| Target Encoding | `category_encoders` | Replaces categories with target mean. |
| Leave-One-Out Encoding | `category_encoders` | Similar to target encoding but avoids data leakage. |

Each encoded dataset was stored for further use:
- `Crop_Mod_OneH_MinMax.csv`
- `Crop_Mod_OneH_Stand.csv`

---

### 4Ô∏è‚É£ Feature Scaling
Two normalization techniques were tested:

| Scaling Method | Library | Description |
|----------------|----------|-------------|
| **MinMaxScaler** | `sklearn.preprocessing.MinMaxScaler` | Scales features to a fixed [0,1] range. |
| **StandardScaler** | `sklearn.preprocessing.StandardScaler` | Standardizes data (zero mean, unit variance). |

Both scaling methods were compared to observe impact on model performance.

---

### 5Ô∏è‚É£ Model Training and Evaluation
A wide range of **regression models** were trained and compared on both scaled datasets.

#### üß© Models Used
- **Linear Regression**
- **Decision Tree Regressor**
- **Random Forest Regressor**
- **XGBoost Regressor**
- **LightGBM Regressor**
- **CatBoost Regressor**
- **AdaBoost Regressor**

#### üßÆ Evaluation Metrics
Each model was evaluated using:
- **RMSE (Root Mean Squared Error)**
- **MAE (Mean Absolute Error)**
- **R¬≤ Score (Coefficient of Determination)**

Results were stored as DataFrames for both scaling approaches:
- `res` ‚Üí MinMax scaled results  
- `res2` ‚Üí Standard scaled results

---

### 6Ô∏è‚É£ End-to-End ML Pipeline
A fully automated **ML pipeline** was built using `scikit-learn` pipelines for robust preprocessing and prediction.

#### üîß Pipeline Components
1. **Custom Date Feature Extractor**
   - Extracts `year`, `month`, `day` from the `Date` column using a custom `TransformerMixin`.

2. **ColumnTransformer**
   - Scales numeric features using `StandardScaler`.
   - Encodes categorical features (`Crop_Type`, `Soil_Type`) using `OneHotEncoder`.

3. **Regressor**
   - A `CatBoostRegressor` model with tuned hyperparameters.

#### ‚ö° Pipeline Steps
```python
Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", CatBoostRegressor(...))
])
```

---

### 7Ô∏è‚É£ Model Persistence
Trained pipeline saved using Joblib:
```python
joblib.dump(model, "RandomReg.pkl")
```
Reloaded seamlessly for predictions:
```python
loaded_model = joblib.load("RandomReg.pkl")
```

---

## üßæ Approach Summary
- Data Cleaning ‚Üí Removed zeros, handled missing values, standardized columns.

- Exploratory Analysis ‚Üí Identified key variable relationships.

- Feature Engineering ‚Üí Extracted date components, scaled numeric features, encoded categorical ones.

- Model Comparison ‚Üí Benchmarked multiple regression models using standard metrics.

- Best Model Selection ‚Üí CatBoostRegressor delivered the most stable and accurate results.

- Pipeline Deployment ‚Üí Implemented automated preprocessing + prediction pipeline.

- Serialization ‚Üí Saved and reloaded model for reuse or API integration.


---

# Time Series Models

## üìò Project Overview
This project focuses on **forecasting crop yield** over time using a combination of **classical statistical models (SARIMAX, ARIMA)** and **machine learning-based time series forecasting (Prophet)**.  
The objective is to predict future crop yields based on historical data and environmental factors such as **Temperature, Humidity, Wind Speed, N, P, K, Soil Quality**, and **Soil pH**.

---

## üß© Dataset
The dataset (`crop_yield_dataset.csv`) contains daily records of crop yields and related features.

### Key Columns:
- `Date` ‚Äî Timestamp of observation  
- `Crop_Yield` ‚Äî Yield value (target variable)  
- `Temperature`, `Humidity`, `Wind_Speed` ‚Äî Weather parameters  
- `N`, `P`, `K` ‚Äî Soil nutrient levels  
- `Soil_pH`, `Soil_Quality` ‚Äî Soil characteristics  

Rows with `Crop_Yield = 0` were removed to ensure data quality.

---

## ‚öôÔ∏è Preprocessing Steps
1. **Data Cleaning**
   - Dropped categorical columns: `Crop_Type`, `Soil_Type`.
   - Removed zero-yield records.
2. **Datetime Indexing**
   - Converted `Date` column to datetime.
   - Set it as index for time series operations.
3. **Resampling**
   - Resampled the data to a **daily frequency** to ensure regular intervals.
4. **Handling Missing Values**
   - Used **mean interpolation** for smooth continuity in Prophet.

---

## üîç Exploratory Data Analysis (EDA)
- Visualized overall trends in crop yield.
- Conducted **stationarity checks** using:
  - **ADF (Augmented Dickey‚ÄìFuller)** test.
  - **KPSS (Kwiatkowski‚ÄìPhillips‚ÄìSchmidt‚ÄìShin)** test.
- Plotted **ACF** and **PACF** graphs to understand autocorrelation and partial autocorrelation.

---

## üß† Model Building

### 1Ô∏è‚É£ SARIMAX Model
- Model: `SARIMAX(order=(1,0,1))`
- Trained on 90% of data, forecasted next 20 days.
- Captured short-term temporal dependencies.

### 2Ô∏è‚É£ ARIMA Model
- Model: `ARIMA(order=(1,1,1))`
- Used differencing to ensure stationarity.
- Diagnostic plots generated to validate residual normality and homoscedasticity.

### 3Ô∏è‚É£ Prophet Model (with Regressors)
- Model: `Prophet()` from Facebook‚Äôs Prophet library.
- Added multiple environmental regressors:
  ```python
  ['Soil_pH', 'Temperature', 'Humidity', 'Wind_Speed', 'N', 'P', 'K', 'Soil_Quality']

---
